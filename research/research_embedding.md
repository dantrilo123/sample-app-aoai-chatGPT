
# Azure テキスト埋め込みモデル比較調査：Small vs Large

## 概要

以下の2つのOpenAIテキスト埋め込みモデルの比較実験結果をまとめました：

| モデル | 次元数 | ベクターインデックス使用量 | 合計ストレージサイズ | ドキュメント数 |
|:------:|:------:|:------------------------:|:------------------:|:------------:|
| **text-embedding-3-small** | 1,536 | 328.33KB | 1.6MB | 54 |
| **text-embedding-3-large** | 3,072 | 653.19KB | 2.71MB | 54 |

## 実験設定

### 共通スキルセット設定

| 設定項目 | 値 |
|:-------:|:--:|
| チャンク最大長 | 2,000文字 |
| オーバーラップ | 500文字 |
| 言語コード | 日本語（ja） |
| テキスト分割モード | pages |

## 検索実験結果

### セマンティックランカー：有効

#### テストケース1：「Neuronの導入事例を探してください」

| 順位 | Small モデルスコア | Large モデルスコア | 一致性 |
|:----:|:-----------------:|:-----------------:|:-----:|
| 1位 | 0.994 | 0.994 | ? 完全一致 |
| 2位 | 0.944 | 0.944 | ? 完全一致 |
| 3位 | 0.944 | 0.941 | ?? わずかな差異 |

#### テストケース2：「ニューロンの導入事例を探してください」（表記違い）

| 順位 | Small モデルスコア | Large モデルスコア | 一致性 |
|:----:|:-----------------:|:-----------------:|:-----:|
| 1位 | 0.987 | 0.987 | ? 完全一致 |
| 2位 | 0.957 | 0.956 | ?? わずかな差異 |
| 3位 | 0.956 | 0.956 | ? 完全一致 |

### セマンティックランカー：無効

| クエリ | Small モデルスコア | Large モデルスコア | 差異 |
|:------:|:-----------------:|:-----------------:|:----:|
| 「Neuronの導入事例」 | 0.593 | 0.596 | +0.003 |
| 「ニューロンの導入事例」 | 0.653 | 0.690 | +0.037 |

## 主な発見

1. **パフォーマンスの同等性**：
    - セマンティックランカー有効時、両モデルはほぼ同一の検索結果とスコアを返した
    - 最上位結果の内容とハイライトも非常に類似

2. **ストレージ効率**：
    - Small モデルはLarge モデルの約1/2のストレージ容量で運用可能
    - 同じドキュメント数でもベクターインデックスサイズに差がある（328KB vs 653KB）

3. **わずかな違い**：
    - セマンティックランカー無効時、Large モデルがわずかに高いスコアを示す
    - 特に「ニューロン」という表記違いのクエリで差が大きくなる（+0.037）

## 結論と推奨事項

- **コスト効率**：日本語ドキュメントの検索用途では、Small モデルでも十分な性能が得られる
- **用途に応じた選択**：
    - 一般的な検索用途 → **Small モデル**
    - 微妙なニュアンスや表記違いへの対応が重要な場合 → **Large モデル**の検討
- **リソース効率**：ストレージコストが懸念される場合は、Small モデルが若干有利


[mainに戻る](https://github.com/brains-technology/sample-app-aoai-chatGPT/blob/branch-1/research/research_main.md)